{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541208a6",
   "metadata": {},
   "source": [
    "## 多任务模型: 模糊图片 → SR修复 → 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a4e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "from NetSet import SRNet, ClassifyNet\n",
    "from datasets import CIFAR10Dataset, Fuzz\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "save_dir = \"results/multi\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std  = (0.2023, 0.1994, 0.2010)\n",
    "normalize = transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "\n",
    "class MultiTaskNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sr = SRNet()\n",
    "        self.classifier = ClassifyNet()\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, x):\n",
    "        sr_out = self.sr(x)\n",
    "        sr_norm = self.normalize(sr_out)\n",
    "        cls_out = self.classifier(sr_norm)\n",
    "        return sr_out, cls_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a33dae2",
   "metadata": {},
   "source": [
    "## 加载预训练权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c98fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预训练权重加载完成\n"
     ]
    }
   ],
   "source": [
    "model = MultiTaskNet().to(device)\n",
    "\n",
    "model.sr.load_state_dict(\n",
    "    torch.load(\"results/task1/model_epoch_100.pth\", map_location=device))\n",
    "\n",
    "model.classifier.load_state_dict(\n",
    "    torch.load(\"results/task2/model_epoch_100.pth\", map_location=device))\n",
    "\n",
    "print(\"预训练权重加载完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b89dd5",
   "metadata": {},
   "source": [
    "## 联合微调训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9913ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/50] SR: 0.04358 | CLS: 0.73513 | Train: 75.56% | Test: 77.04%\n",
      "Epoch [  2/50] SR: 0.04225 | CLS: 0.64552 | Train: 78.29% | Test: 77.38%\n",
      "Epoch [  3/50] SR: 0.04131 | CLS: 0.61887 | Train: 79.05% | Test: 78.73%\n",
      "Epoch [  4/50] SR: 0.04128 | CLS: 0.60075 | Train: 79.69% | Test: 78.71%\n",
      "Epoch [  5/50] SR: 0.04080 | CLS: 0.58526 | Train: 80.16% | Test: 79.39%\n",
      "Epoch [  6/50] SR: 0.04053 | CLS: 0.56218 | Train: 81.08% | Test: 79.03%\n",
      "Epoch [  7/50] SR: 0.04036 | CLS: 0.55823 | Train: 81.07% | Test: 79.35%\n",
      "Epoch [  8/50] SR: 0.04043 | CLS: 0.54553 | Train: 81.60% | Test: 79.25%\n",
      "Epoch [  9/50] SR: 0.04017 | CLS: 0.53246 | Train: 82.12% | Test: 80.08%\n",
      "Epoch [ 10/50] SR: 0.04041 | CLS: 0.52181 | Train: 82.61% | Test: 79.89%\n",
      "Epoch [ 11/50] SR: 0.04031 | CLS: 0.51273 | Train: 82.68% | Test: 80.36%\n",
      "Epoch [ 12/50] SR: 0.03995 | CLS: 0.49916 | Train: 83.10% | Test: 79.45%\n",
      "Epoch [ 13/50] SR: 0.04014 | CLS: 0.49414 | Train: 83.23% | Test: 79.86%\n",
      "Epoch [ 14/50] SR: 0.04004 | CLS: 0.48610 | Train: 83.46% | Test: 80.60%\n",
      "Epoch [ 15/50] SR: 0.04030 | CLS: 0.47843 | Train: 83.56% | Test: 80.33%\n",
      "Epoch [ 16/50] SR: 0.04068 | CLS: 0.47548 | Train: 84.06% | Test: 78.89%\n",
      "Epoch [ 17/50] SR: 0.03980 | CLS: 0.46677 | Train: 84.27% | Test: 80.47%\n",
      "Epoch [ 18/50] SR: 0.03974 | CLS: 0.45854 | Train: 84.39% | Test: 79.99%\n",
      "Epoch [ 19/50] SR: 0.04006 | CLS: 0.45496 | Train: 84.70% | Test: 80.54%\n",
      "Epoch [ 20/50] SR: 0.04026 | CLS: 0.45169 | Train: 84.76% | Test: 80.61%\n",
      "Epoch [ 21/50] SR: 0.03986 | CLS: 0.44239 | Train: 84.92% | Test: 80.78%\n",
      "Epoch [ 22/50] SR: 0.04005 | CLS: 0.44085 | Train: 85.03% | Test: 80.43%\n",
      "Epoch [ 23/50] SR: 0.04039 | CLS: 0.42960 | Train: 85.32% | Test: 80.27%\n",
      "Epoch [ 24/50] SR: 0.03997 | CLS: 0.42035 | Train: 85.65% | Test: 80.29%\n",
      "Epoch [ 25/50] SR: 0.04003 | CLS: 0.42115 | Train: 85.56% | Test: 80.88%\n",
      "Epoch [ 26/50] SR: 0.04048 | CLS: 0.41328 | Train: 86.00% | Test: 80.25%\n",
      "Epoch [ 27/50] SR: 0.04024 | CLS: 0.40998 | Train: 86.16% | Test: 80.83%\n",
      "Epoch [ 28/50] SR: 0.04020 | CLS: 0.40715 | Train: 86.18% | Test: 80.31%\n",
      "Epoch [ 29/50] SR: 0.03996 | CLS: 0.39938 | Train: 86.29% | Test: 80.93%\n",
      "Epoch [ 30/50] SR: 0.03967 | CLS: 0.39075 | Train: 86.68% | Test: 80.28%\n",
      "Epoch [ 31/50] SR: 0.04045 | CLS: 0.39565 | Train: 86.57% | Test: 80.50%\n",
      "Epoch [ 32/50] SR: 0.04010 | CLS: 0.38649 | Train: 86.92% | Test: 81.06%\n",
      "Epoch [ 33/50] SR: 0.04038 | CLS: 0.38424 | Train: 86.93% | Test: 81.27%\n",
      "Epoch [ 34/50] SR: 0.04041 | CLS: 0.37328 | Train: 87.17% | Test: 81.16%\n",
      "Epoch [ 35/50] SR: 0.04024 | CLS: 0.37450 | Train: 87.20% | Test: 81.07%\n",
      "Epoch [ 36/50] SR: 0.04024 | CLS: 0.36574 | Train: 87.46% | Test: 80.84%\n",
      "Epoch [ 37/50] SR: 0.04022 | CLS: 0.36566 | Train: 87.59% | Test: 81.05%\n",
      "Epoch [ 38/50] SR: 0.04045 | CLS: 0.36043 | Train: 87.65% | Test: 81.39%\n",
      "Epoch [ 39/50] SR: 0.04048 | CLS: 0.35641 | Train: 87.64% | Test: 81.23%\n",
      "Epoch [ 40/50] SR: 0.04048 | CLS: 0.35233 | Train: 87.92% | Test: 81.44%\n",
      "Epoch [ 41/50] SR: 0.04052 | CLS: 0.35204 | Train: 87.85% | Test: 80.93%\n",
      "Epoch [ 42/50] SR: 0.04060 | CLS: 0.34608 | Train: 88.27% | Test: 81.36%\n",
      "Epoch [ 43/50] SR: 0.04051 | CLS: 0.34358 | Train: 88.23% | Test: 81.08%\n",
      "Epoch [ 44/50] SR: 0.04036 | CLS: 0.33869 | Train: 88.38% | Test: 81.00%\n",
      "Epoch [ 45/50] SR: 0.04044 | CLS: 0.33357 | Train: 88.73% | Test: 81.11%\n",
      "Epoch [ 46/50] SR: 0.04035 | CLS: 0.33263 | Train: 88.62% | Test: 80.68%\n",
      "Epoch [ 47/50] SR: 0.04028 | CLS: 0.32895 | Train: 88.82% | Test: 81.13%\n",
      "Epoch [ 48/50] SR: 0.04023 | CLS: 0.32644 | Train: 88.85% | Test: 81.18%\n",
      "Epoch [ 49/50] SR: 0.04039 | CLS: 0.31786 | Train: 89.19% | Test: 81.53%\n",
      "Epoch [ 50/50] SR: 0.04063 | CLS: 0.31880 | Train: 89.21% | Test: 80.95%\n",
      "保存至 results/multi/\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 50 \n",
    "lr = 0.0005\n",
    "momentum = 0.9\n",
    "lambda_sr = 1.0\n",
    "lambda_cls = 1.0\n",
    "\n",
    "train_dataset = CIFAR10Dataset(root_dir='./DS/CIFAR10', train=True)\n",
    "test_dataset  = CIFAR10Dataset(root_dir='./DS/CIFAR10', train=False)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "fuzz = Fuzz(scale_factor=2)\n",
    "\n",
    "inv_mean = torch.tensor(cifar10_mean).view(3,1,1).to(device)\n",
    "inv_std  = torch.tensor(cifar10_std).view(3,1,1).to(device)\n",
    "\n",
    "def denormalize(x):\n",
    "    return x * inv_std + inv_mean\n",
    "\n",
    "sr_criterion  = nn.L1Loss()\n",
    "cls_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_sr_loss = 0\n",
    "    epoch_cls_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        clean = denormalize(inputs)\n",
    "        blurry = torch.stack([fuzz(img) for img in clean]).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sr_out, cls_out = model(blurry)\n",
    "\n",
    "        loss_sr  = sr_criterion(sr_out, clean)\n",
    "        loss_cls = cls_criterion(cls_out, labels)\n",
    "        loss = lambda_sr * loss_sr + lambda_cls * loss_cls\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_sr_loss  += loss_sr.item()\n",
    "        epoch_cls_loss += loss_cls.item()\n",
    "        _, predicted = torch.max(cls_out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_sr  = epoch_sr_loss / len(train_loader)\n",
    "    avg_cls = epoch_cls_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            clean = denormalize(inputs)\n",
    "            blurry = torch.stack([fuzz(img) for img in clean]).to(device)\n",
    "            _, cls_out = model(blurry)\n",
    "            _, predicted = torch.max(cls_out.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1:3d}/{epochs}] SR: {avg_sr:.5f} | CLS: {avg_cls:.5f} | Train: {train_acc:.2f}% | Test: {test_acc:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"{save_dir}/multi_model.pth\")\n",
    "print(f\"保存至 {save_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c833496",
   "metadata": {},
   "source": [
    "## 对比: 模糊直接分类 vs 多任务(SR+分类)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb5cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清晰图直接分类:       84.80%\n",
      "低分辨率图直接分类:  47.26%\n",
      "低分辨率图 → 超分 → 分类:       80.95%\n",
      "提升: +33.69%\n"
     ]
    }
   ],
   "source": [
    "baseline = ClassifyNet().to(device)\n",
    "baseline.load_state_dict(torch.load(\"results/task2/model_epoch_100.pth\", map_location=device))\n",
    "baseline.eval()\n",
    "model.eval()\n",
    "\n",
    "acc_baseline = 0\n",
    "acc_multi = 0\n",
    "acc_clean = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        clean = denormalize(inputs)\n",
    "        blurry = torch.stack([fuzz(img) for img in clean]).to(device)\n",
    "\n",
    "        upscaled = nn.functional.interpolate(blurry, scale_factor=2, mode='bicubic', align_corners=False)\n",
    "        upscaled_norm = normalize(upscaled)\n",
    "        pred_baseline = baseline(upscaled_norm).argmax(dim=1)\n",
    "\n",
    "        _, cls_out = model(blurry)\n",
    "        pred_multi = cls_out.argmax(dim=1)\n",
    "\n",
    "        pred_clean = baseline(inputs).argmax(dim=1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        acc_baseline += (pred_baseline == labels).sum().item()\n",
    "        acc_multi    += (pred_multi == labels).sum().item()\n",
    "        acc_clean    += (pred_clean == labels).sum().item()\n",
    "\n",
    "acc_baseline = 100 * acc_baseline / total\n",
    "acc_multi    = 100 * acc_multi / total\n",
    "acc_clean    = 100 * acc_clean / total\n",
    "\n",
    "print(f\"清晰图直接分类:       {acc_clean:.2f}%\")\n",
    "print(f\"低分辨率图直接分类:  {acc_baseline:.2f}%\")\n",
    "print(f\"低分辨率图 → 超分 → 分类:       {acc_multi:.2f}%\")\n",
    "print(f\"提升: {acc_multi - acc_baseline:+.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

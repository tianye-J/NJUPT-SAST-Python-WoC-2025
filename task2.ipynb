{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入模块与超参数设置\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 训练超参数\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "log_interval = 100  # 每 100 个 batch 输出一次损失\n",
    "\n",
    "# 数据归一化参数\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std = (0.2023, 0.1994, 0.2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e5d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./CIFAR10',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./CIFAR10',\n",
    "                                 train=False,\n",
    "                                 download=True,\n",
    "                                 transform=transform)\n",
    "                \n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         shuffle=False,\n",
    "                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbf810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=800, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义模型\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # CIFAR10 输入: (batch, 3, 32, 32)\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 5 * 5)  # 展平\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552fda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77f84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练函数\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % log_interval == log_interval - 1:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {batch_idx + 1}] loss: {running_loss / log_interval:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e44b0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试函数\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c03e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 100] loss: 2.237\n",
      "[Epoch 1, Batch 200] loss: 1.932\n",
      "[Epoch 1, Batch 300] loss: 1.707\n",
      "[Epoch 1, Batch 400] loss: 1.559\n",
      "[Epoch 1, Batch 500] loss: 1.507\n",
      "[Epoch 1, Batch 600] loss: 1.444\n",
      "[Epoch 1, Batch 700] loss: 1.421\n",
      "Accuracy on test set: 50.34%\n",
      "[Epoch 2, Batch 100] loss: 1.322\n",
      "[Epoch 2, Batch 200] loss: 1.297\n",
      "[Epoch 2, Batch 300] loss: 1.258\n",
      "[Epoch 2, Batch 400] loss: 1.229\n",
      "[Epoch 2, Batch 500] loss: 1.201\n",
      "[Epoch 2, Batch 600] loss: 1.178\n",
      "[Epoch 2, Batch 700] loss: 1.162\n",
      "Accuracy on test set: 57.59%\n",
      "[Epoch 3, Batch 100] loss: 1.104\n",
      "[Epoch 3, Batch 200] loss: 1.050\n",
      "[Epoch 3, Batch 300] loss: 1.068\n",
      "[Epoch 3, Batch 400] loss: 1.031\n",
      "[Epoch 3, Batch 500] loss: 1.073\n",
      "[Epoch 3, Batch 600] loss: 1.010\n",
      "[Epoch 3, Batch 700] loss: 1.003\n",
      "Accuracy on test set: 61.18%\n",
      "[Epoch 4, Batch 100] loss: 0.937\n",
      "[Epoch 4, Batch 200] loss: 0.934\n",
      "[Epoch 4, Batch 300] loss: 0.916\n",
      "[Epoch 4, Batch 400] loss: 0.906\n",
      "[Epoch 4, Batch 500] loss: 0.935\n",
      "[Epoch 4, Batch 600] loss: 0.926\n",
      "[Epoch 4, Batch 700] loss: 0.926\n",
      "Accuracy on test set: 66.49%\n",
      "[Epoch 5, Batch 100] loss: 0.800\n",
      "[Epoch 5, Batch 200] loss: 0.825\n",
      "[Epoch 5, Batch 300] loss: 0.843\n",
      "[Epoch 5, Batch 400] loss: 0.824\n",
      "[Epoch 5, Batch 500] loss: 0.822\n",
      "[Epoch 5, Batch 600] loss: 0.884\n",
      "[Epoch 5, Batch 700] loss: 0.847\n",
      "Accuracy on test set: 67.87%\n",
      "[Epoch 6, Batch 100] loss: 0.725\n",
      "[Epoch 6, Batch 200] loss: 0.739\n",
      "[Epoch 6, Batch 300] loss: 0.728\n",
      "[Epoch 6, Batch 400] loss: 0.754\n",
      "[Epoch 6, Batch 500] loss: 0.735\n",
      "[Epoch 6, Batch 600] loss: 0.769\n",
      "[Epoch 6, Batch 700] loss: 0.824\n",
      "Accuracy on test set: 68.72%\n",
      "[Epoch 7, Batch 100] loss: 0.655\n",
      "[Epoch 7, Batch 200] loss: 0.670\n",
      "[Epoch 7, Batch 300] loss: 0.716\n",
      "[Epoch 7, Batch 400] loss: 0.695\n",
      "[Epoch 7, Batch 500] loss: 0.714\n",
      "[Epoch 7, Batch 600] loss: 0.736\n",
      "[Epoch 7, Batch 700] loss: 0.728\n",
      "Accuracy on test set: 68.57%\n",
      "[Epoch 8, Batch 100] loss: 0.625\n",
      "[Epoch 8, Batch 200] loss: 0.623\n",
      "[Epoch 8, Batch 300] loss: 0.629\n",
      "[Epoch 8, Batch 400] loss: 0.679\n",
      "[Epoch 8, Batch 500] loss: 0.657\n",
      "[Epoch 8, Batch 600] loss: 0.656\n",
      "[Epoch 8, Batch 700] loss: 0.703\n",
      "Accuracy on test set: 70.20%\n",
      "[Epoch 9, Batch 100] loss: 0.559\n",
      "[Epoch 9, Batch 200] loss: 0.552\n",
      "[Epoch 9, Batch 300] loss: 0.565\n",
      "[Epoch 9, Batch 400] loss: 0.601\n",
      "[Epoch 9, Batch 500] loss: 0.610\n",
      "[Epoch 9, Batch 600] loss: 0.611\n",
      "[Epoch 9, Batch 700] loss: 0.633\n",
      "Accuracy on test set: 68.92%\n",
      "[Epoch 10, Batch 100] loss: 0.506\n",
      "[Epoch 10, Batch 200] loss: 0.499\n",
      "[Epoch 10, Batch 300] loss: 0.555\n",
      "[Epoch 10, Batch 400] loss: 0.543\n",
      "[Epoch 10, Batch 500] loss: 0.610\n",
      "[Epoch 10, Batch 600] loss: 0.591\n",
      "[Epoch 10, Batch 700] loss: 0.602\n",
      "Accuracy on test set: 68.78%\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

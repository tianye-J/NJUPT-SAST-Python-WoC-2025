{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bfa596",
   "metadata": {},
   "source": [
    "# ğŸ–¼ï¸ CIFAR-10 å›¾åƒåˆ†ç±»ä»»åŠ¡ (Task 2)\n",
    "\n",
    "## ğŸ“‹ é¡¹ç›®æ¦‚è¿°\n",
    "æœ¬é¡¹ç›®å®ç°äº†åŸºäºæ·±åº¦å­¦ä¹ çš„ CIFAR-10 å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œå¯¹ 10 ç±»å½©è‰²å›¾åƒè¿›è¡Œåˆ†ç±»è¯†åˆ«ã€‚\n",
    "\n",
    "## ğŸ¯ ä»»åŠ¡ç›®æ ‡\n",
    "- **æ•°æ®é›†**ï¼šCIFAR-10ï¼ˆ60,000 å¼  32Ã—32 å½©è‰²å›¾åƒï¼‰\n",
    "- **ç±»åˆ«æ•°**ï¼š10 ç±»ï¼ˆé£æœºã€æ±½è½¦ã€é¸Ÿã€çŒ«ã€é¹¿ã€ç‹—ã€é’è›™ã€é©¬ã€èˆ¹ã€å¡è½¦ï¼‰\n",
    "- **æ¨¡å‹æ¶æ„**ï¼šåŸºç¡€ CNNï¼ˆå·ç§¯ç¥ç»ç½‘ç»œ + å…¨è¿æ¥å±‚ï¼‰\n",
    "- **ç›®æ ‡å‡†ç¡®ç‡**ï¼š67% ~ 69%\n",
    "\n",
    "## ğŸ—ï¸ æ¨¡å‹ç»“æ„\n",
    "```\n",
    "è¾“å…¥ (3Ã—32Ã—32) \n",
    "  â†“\n",
    "Conv1 (16 filters, 5Ã—5) + ReLU + MaxPool\n",
    "  â†“\n",
    "Conv2 (32 filters, 5Ã—5) + ReLU + MaxPool\n",
    "  â†“\n",
    "Flatten\n",
    "  â†“\n",
    "FC1 (120) + ReLU\n",
    "  â†“\n",
    "FC2 (84) + ReLU\n",
    "  â†“\n",
    "FC3 (10) â†’ è¾“å‡º\n",
    "```\n",
    "\n",
    "## ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹\n",
    "- âœ… æ•°æ®å½’ä¸€åŒ–å¤„ç†ï¼ˆä½¿ç”¨ CIFAR-10 å‡å€¼å’Œæ ‡å‡†å·®ï¼‰\n",
    "- âœ… GPU åŠ é€Ÿè®­ç»ƒæ”¯æŒ\n",
    "- âœ… å®æ—¶è®­ç»ƒæŸå¤±ç›‘æ§\n",
    "- âœ… æµ‹è¯•é›†å‡†ç¡®ç‡è¯„ä¼°\n",
    "- âœ… ç®€æ´é«˜æ•ˆçš„ä»£ç ç»“æ„\n",
    "\n",
    "## ğŸ“Š è®­ç»ƒé…ç½®\n",
    "| å‚æ•° | å€¼ |\n",
    "|------|-----|\n",
    "| Batch Size | 64 |\n",
    "| Epochs | 10 |\n",
    "| Learning Rate | 0.01 |\n",
    "| Optimizer | SGD (momentum=0.9) |\n",
    "| Loss Function | CrossEntropyLoss |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381f6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#å¯¼å…¥æ¨¡å—ä¸è¶…å‚æ•°è®¾ç½®\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# è®­ç»ƒè¶…å‚æ•°\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "log_interval = 100  # æ¯ 100 ä¸ª batch è¾“å‡ºä¸€æ¬¡æŸå¤±\n",
    "\n",
    "# æ•°æ®å½’ä¸€åŒ–å‚æ•°\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std = (0.2023, 0.1994, 0.2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e5d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ•°æ®é¢„å¤„ç†\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./CIFAR10',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./CIFAR10',\n",
    "                                 train=False,\n",
    "                                 download=True,\n",
    "                                 transform=transform)\n",
    "                \n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         shuffle=False,\n",
    "                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbbf810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=800, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#å®šä¹‰æ¨¡å‹\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # CIFAR10 è¾“å…¥: (batch, 3, 32, 32)\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 5 * 5)  # å±•å¹³\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552fda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77f84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#è®­ç»ƒå‡½æ•°\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % log_interval == log_interval - 1:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {batch_idx + 1}] loss: {running_loss / log_interval:.3f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44b0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æµ‹è¯•å‡½æ•°\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c03e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 100] loss: 2.257\n",
      "[Epoch 1, Batch 200] loss: 1.915\n",
      "[Epoch 1, Batch 300] loss: 1.682\n",
      "[Epoch 1, Batch 400] loss: 1.566\n",
      "[Epoch 1, Batch 500] loss: 1.537\n",
      "[Epoch 1, Batch 600] loss: 1.454\n",
      "[Epoch 1, Batch 700] loss: 1.395\n",
      "Accuracy on test set: 50.08%\n",
      "[Epoch 2, Batch 100] loss: 1.294\n",
      "[Epoch 2, Batch 200] loss: 1.293\n",
      "[Epoch 2, Batch 300] loss: 1.264\n",
      "[Epoch 2, Batch 400] loss: 1.260\n",
      "[Epoch 2, Batch 500] loss: 1.208\n",
      "[Epoch 2, Batch 600] loss: 1.196\n",
      "[Epoch 2, Batch 700] loss: 1.189\n",
      "Accuracy on test set: 56.63%\n",
      "[Epoch 3, Batch 100] loss: 1.073\n",
      "[Epoch 3, Batch 200] loss: 1.082\n",
      "[Epoch 3, Batch 300] loss: 1.052\n",
      "[Epoch 3, Batch 400] loss: 1.108\n",
      "[Epoch 3, Batch 500] loss: 1.069\n",
      "[Epoch 3, Batch 600] loss: 1.043\n",
      "[Epoch 3, Batch 700] loss: 1.051\n",
      "Accuracy on test set: 63.12%\n",
      "[Epoch 4, Batch 100] loss: 0.937\n",
      "[Epoch 4, Batch 200] loss: 0.978\n",
      "[Epoch 4, Batch 300] loss: 0.921\n",
      "[Epoch 4, Batch 400] loss: 0.986\n",
      "[Epoch 4, Batch 500] loss: 0.943\n",
      "[Epoch 4, Batch 600] loss: 0.943\n",
      "[Epoch 4, Batch 700] loss: 0.914\n",
      "Accuracy on test set: 65.09%\n",
      "[Epoch 5, Batch 100] loss: 0.836\n",
      "[Epoch 5, Batch 200] loss: 0.829\n",
      "[Epoch 5, Batch 300] loss: 0.856\n",
      "[Epoch 5, Batch 400] loss: 0.883\n",
      "[Epoch 5, Batch 500] loss: 0.857\n",
      "[Epoch 5, Batch 600] loss: 0.875\n",
      "[Epoch 5, Batch 700] loss: 0.854\n",
      "Accuracy on test set: 66.98%\n",
      "[Epoch 6, Batch 100] loss: 0.767\n",
      "[Epoch 6, Batch 200] loss: 0.749\n",
      "[Epoch 6, Batch 300] loss: 0.790\n",
      "[Epoch 6, Batch 400] loss: 0.798\n",
      "[Epoch 6, Batch 500] loss: 0.792\n",
      "[Epoch 6, Batch 600] loss: 0.775\n",
      "[Epoch 6, Batch 700] loss: 0.810\n",
      "Accuracy on test set: 66.40%\n",
      "[Epoch 7, Batch 100] loss: 0.684\n",
      "[Epoch 7, Batch 200] loss: 0.712\n",
      "[Epoch 7, Batch 300] loss: 0.723\n",
      "[Epoch 7, Batch 400] loss: 0.702\n",
      "[Epoch 7, Batch 500] loss: 0.730\n",
      "[Epoch 7, Batch 600] loss: 0.745\n",
      "[Epoch 7, Batch 700] loss: 0.722\n",
      "Accuracy on test set: 66.06%\n",
      "[Epoch 8, Batch 100] loss: 0.628\n",
      "[Epoch 8, Batch 200] loss: 0.646\n",
      "[Epoch 8, Batch 300] loss: 0.643\n",
      "[Epoch 8, Batch 400] loss: 0.676\n",
      "[Epoch 8, Batch 500] loss: 0.677\n",
      "[Epoch 8, Batch 600] loss: 0.692\n",
      "[Epoch 8, Batch 700] loss: 0.712\n",
      "Accuracy on test set: 68.42%\n",
      "[Epoch 9, Batch 100] loss: 0.571\n",
      "[Epoch 9, Batch 200] loss: 0.580\n",
      "[Epoch 9, Batch 300] loss: 0.616\n",
      "[Epoch 9, Batch 400] loss: 0.639\n",
      "[Epoch 9, Batch 500] loss: 0.623\n",
      "[Epoch 9, Batch 600] loss: 0.628\n",
      "[Epoch 9, Batch 700] loss: 0.659\n",
      "Accuracy on test set: 69.10%\n",
      "[Epoch 10, Batch 100] loss: 0.545\n",
      "[Epoch 10, Batch 200] loss: 0.542\n",
      "[Epoch 10, Batch 300] loss: 0.596\n",
      "[Epoch 10, Batch 400] loss: 0.568\n",
      "[Epoch 10, Batch 500] loss: 0.597\n",
      "[Epoch 10, Batch 600] loss: 0.599\n",
      "[Epoch 10, Batch 700] loss: 0.598\n",
      "Accuracy on test set: 68.61%\n"
     ]
    }
   ],
   "source": [
    "#å¼€å§‹è®­ç»ƒ\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

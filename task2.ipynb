{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381f6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入模块与超参数设置\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# 训练超参数\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "save_dir = \"results/task2\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e5d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: 50000 张图片\n",
      "测试集: 10000 张图片\n",
      "类别: ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "from datasets import CIFAR10Dataset\n",
    "\n",
    "train_dataset = CIFAR10Dataset(root_dir='./DS/CIFAR10', train=True)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_dataset = CIFAR10Dataset(root_dir='./DS/CIFAR10', train=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "print(f\"训练集: {len(train_dataset)} 张图片\")\n",
    "print(f\"测试集: {len(test_dataset)} 张图片\")\n",
    "print(f\"类别: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbbf810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "# Task2: 分类网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "        self.dropout_conv = nn.Dropout(0.25)\n",
    "        self.dropout_fc = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout_fc(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#准备模型、Loss、优化器\n",
    "model = Net()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77f84f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  1/100] Loss: 2.30303 | Train: 9.94% | Test: 10.93%\n",
      "Epoch [  2/100] Loss: 2.30270 | Train: 10.04% | Test: 12.48%\n",
      "Epoch [  3/100] Loss: 2.30258 | Train: 9.95% | Test: 16.58%\n",
      "Epoch [  4/100] Loss: 2.30208 | Train: 10.67% | Test: 15.39%\n",
      "Epoch [  5/100] Loss: 2.30089 | Train: 11.29% | Test: 15.98%\n",
      "Epoch [  6/100] Loss: 2.27828 | Train: 13.87% | Test: 19.43%\n",
      "Epoch [  7/100] Loss: 2.15077 | Train: 20.33% | Test: 25.79%\n",
      "Epoch [  8/100] Loss: 2.06396 | Train: 24.18% | Test: 28.03%\n",
      "Epoch [  9/100] Loss: 1.94481 | Train: 26.42% | Test: 29.95%\n",
      "Epoch [ 10/100] Loss: 1.84263 | Train: 28.60% | Test: 33.24%\n",
      "Epoch [ 11/100] Loss: 1.76097 | Train: 32.34% | Test: 38.50%\n",
      "Epoch [ 12/100] Loss: 1.68190 | Train: 35.88% | Test: 41.40%\n",
      "Epoch [ 13/100] Loss: 1.61662 | Train: 38.96% | Test: 43.44%\n",
      "Epoch [ 14/100] Loss: 1.57167 | Train: 41.23% | Test: 45.64%\n",
      "Epoch [ 15/100] Loss: 1.52991 | Train: 43.19% | Test: 47.35%\n",
      "Epoch [ 16/100] Loss: 1.48103 | Train: 44.80% | Test: 47.34%\n",
      "Epoch [ 17/100] Loss: 1.43569 | Train: 47.03% | Test: 50.63%\n",
      "Epoch [ 18/100] Loss: 1.39430 | Train: 48.86% | Test: 54.63%\n",
      "Epoch [ 19/100] Loss: 1.34913 | Train: 50.79% | Test: 55.28%\n",
      "Epoch [ 20/100] Loss: 1.30518 | Train: 52.99% | Test: 56.70%\n",
      "Epoch [ 21/100] Loss: 1.26279 | Train: 54.65% | Test: 57.43%\n",
      "Epoch [ 22/100] Loss: 1.22788 | Train: 56.20% | Test: 59.95%\n",
      "Epoch [ 23/100] Loss: 1.18893 | Train: 57.60% | Test: 61.74%\n",
      "Epoch [ 24/100] Loss: 1.15326 | Train: 59.09% | Test: 62.22%\n",
      "Epoch [ 25/100] Loss: 1.12830 | Train: 59.93% | Test: 63.62%\n",
      "Epoch [ 26/100] Loss: 1.09630 | Train: 61.27% | Test: 64.71%\n",
      "Epoch [ 27/100] Loss: 1.06889 | Train: 62.57% | Test: 64.77%\n",
      "Epoch [ 28/100] Loss: 1.04576 | Train: 63.34% | Test: 66.37%\n",
      "Epoch [ 29/100] Loss: 1.01983 | Train: 64.24% | Test: 67.49%\n",
      "Epoch [ 30/100] Loss: 0.99839 | Train: 65.14% | Test: 68.73%\n",
      "Epoch [ 31/100] Loss: 0.97193 | Train: 66.21% | Test: 69.33%\n",
      "Epoch [ 32/100] Loss: 0.95796 | Train: 66.80% | Test: 68.98%\n",
      "Epoch [ 33/100] Loss: 0.93608 | Train: 67.60% | Test: 70.58%\n",
      "Epoch [ 34/100] Loss: 0.91763 | Train: 68.55% | Test: 69.58%\n",
      "Epoch [ 35/100] Loss: 0.89805 | Train: 68.71% | Test: 71.50%\n",
      "Epoch [ 36/100] Loss: 0.88621 | Train: 69.56% | Test: 71.52%\n",
      "Epoch [ 37/100] Loss: 0.86950 | Train: 70.23% | Test: 72.02%\n",
      "Epoch [ 38/100] Loss: 0.85719 | Train: 70.36% | Test: 71.43%\n",
      "Epoch [ 39/100] Loss: 0.84418 | Train: 70.96% | Test: 73.06%\n",
      "Epoch [ 40/100] Loss: 0.82451 | Train: 71.61% | Test: 73.74%\n",
      "Epoch [ 41/100] Loss: 0.80791 | Train: 72.03% | Test: 74.21%\n",
      "Epoch [ 42/100] Loss: 0.79541 | Train: 72.60% | Test: 74.04%\n",
      "Epoch [ 43/100] Loss: 0.78503 | Train: 73.16% | Test: 74.88%\n",
      "Epoch [ 44/100] Loss: 0.76633 | Train: 73.69% | Test: 75.00%\n",
      "Epoch [ 45/100] Loss: 0.75166 | Train: 74.22% | Test: 76.17%\n",
      "Epoch [ 46/100] Loss: 0.73809 | Train: 74.81% | Test: 75.67%\n",
      "Epoch [ 47/100] Loss: 0.72726 | Train: 75.19% | Test: 76.90%\n",
      "Epoch [ 48/100] Loss: 0.71288 | Train: 75.61% | Test: 76.76%\n",
      "Epoch [ 49/100] Loss: 0.69724 | Train: 76.30% | Test: 77.29%\n",
      "Epoch [ 50/100] Loss: 0.68850 | Train: 76.52% | Test: 77.56%\n",
      "Epoch [ 51/100] Loss: 0.68006 | Train: 76.97% | Test: 78.44%\n",
      "Epoch [ 52/100] Loss: 0.66321 | Train: 77.51% | Test: 78.05%\n",
      "Epoch [ 53/100] Loss: 0.65191 | Train: 77.84% | Test: 78.40%\n",
      "Epoch [ 54/100] Loss: 0.64076 | Train: 78.13% | Test: 79.22%\n",
      "Epoch [ 55/100] Loss: 0.62801 | Train: 78.96% | Test: 78.81%\n",
      "Epoch [ 56/100] Loss: 0.61842 | Train: 79.00% | Test: 78.13%\n",
      "Epoch [ 57/100] Loss: 0.61077 | Train: 79.15% | Test: 79.45%\n",
      "Epoch [ 58/100] Loss: 0.59849 | Train: 79.71% | Test: 79.92%\n",
      "Epoch [ 59/100] Loss: 0.58876 | Train: 79.99% | Test: 79.93%\n",
      "Epoch [ 60/100] Loss: 0.58401 | Train: 80.24% | Test: 79.44%\n",
      "Epoch [ 61/100] Loss: 0.57347 | Train: 80.51% | Test: 78.59%\n",
      "Epoch [ 62/100] Loss: 0.56230 | Train: 81.03% | Test: 80.55%\n",
      "Epoch [ 63/100] Loss: 0.55676 | Train: 81.31% | Test: 81.03%\n",
      "Epoch [ 64/100] Loss: 0.54458 | Train: 81.65% | Test: 81.09%\n",
      "Epoch [ 65/100] Loss: 0.53612 | Train: 81.84% | Test: 81.32%\n",
      "Epoch [ 66/100] Loss: 0.53291 | Train: 82.00% | Test: 81.33%\n",
      "Epoch [ 67/100] Loss: 0.51574 | Train: 82.51% | Test: 81.40%\n",
      "Epoch [ 68/100] Loss: 0.51203 | Train: 82.66% | Test: 80.64%\n",
      "Epoch [ 69/100] Loss: 0.50716 | Train: 83.07% | Test: 81.99%\n",
      "Epoch [ 70/100] Loss: 0.49571 | Train: 83.03% | Test: 80.57%\n",
      "Epoch [ 71/100] Loss: 0.49110 | Train: 83.43% | Test: 82.31%\n",
      "Epoch [ 72/100] Loss: 0.47856 | Train: 83.71% | Test: 81.94%\n",
      "Epoch [ 73/100] Loss: 0.47946 | Train: 83.85% | Test: 82.56%\n",
      "Epoch [ 74/100] Loss: 0.47009 | Train: 84.13% | Test: 82.72%\n",
      "Epoch [ 75/100] Loss: 0.45905 | Train: 84.40% | Test: 82.10%\n",
      "Epoch [ 76/100] Loss: 0.45303 | Train: 84.57% | Test: 83.06%\n",
      "Epoch [ 77/100] Loss: 0.45002 | Train: 84.85% | Test: 83.01%\n",
      "Epoch [ 78/100] Loss: 0.44258 | Train: 84.99% | Test: 82.68%\n",
      "Epoch [ 79/100] Loss: 0.43288 | Train: 85.29% | Test: 82.46%\n",
      "Epoch [ 80/100] Loss: 0.43326 | Train: 85.33% | Test: 83.12%\n",
      "Epoch [ 81/100] Loss: 0.41833 | Train: 85.87% | Test: 83.53%\n",
      "Epoch [ 82/100] Loss: 0.41553 | Train: 86.08% | Test: 83.34%\n",
      "Epoch [ 83/100] Loss: 0.40830 | Train: 86.01% | Test: 83.33%\n",
      "Epoch [ 84/100] Loss: 0.40666 | Train: 86.33% | Test: 83.38%\n",
      "Epoch [ 85/100] Loss: 0.40292 | Train: 86.33% | Test: 83.40%\n",
      "Epoch [ 86/100] Loss: 0.39691 | Train: 86.53% | Test: 84.11%\n",
      "Epoch [ 87/100] Loss: 0.38975 | Train: 86.66% | Test: 83.28%\n",
      "Epoch [ 88/100] Loss: 0.37960 | Train: 87.09% | Test: 83.94%\n",
      "Epoch [ 89/100] Loss: 0.37980 | Train: 87.10% | Test: 83.55%\n",
      "Epoch [ 90/100] Loss: 0.37275 | Train: 87.27% | Test: 83.91%\n",
      "Epoch [ 91/100] Loss: 0.36632 | Train: 87.49% | Test: 84.15%\n",
      "Epoch [ 92/100] Loss: 0.36413 | Train: 87.68% | Test: 84.18%\n",
      "Epoch [ 93/100] Loss: 0.35939 | Train: 87.86% | Test: 84.32%\n",
      "Epoch [ 94/100] Loss: 0.35481 | Train: 87.88% | Test: 84.11%\n",
      "Epoch [ 95/100] Loss: 0.34594 | Train: 88.26% | Test: 84.27%\n",
      "Epoch [ 96/100] Loss: 0.34393 | Train: 88.33% | Test: 84.47%\n",
      "Epoch [ 97/100] Loss: 0.33426 | Train: 88.47% | Test: 84.20%\n",
      "Epoch [ 98/100] Loss: 0.33872 | Train: 88.46% | Test: 84.07%\n",
      "Epoch [ 99/100] Loss: 0.32926 | Train: 88.70% | Test: 84.26%\n",
      "Epoch [100/100] Loss: 0.32176 | Train: 89.08% | Test: 84.80%\n",
      "权重保存至 results/task2/\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # 计算平均指标\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    # 测试集评估\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1:3d}/{epochs}] Loss: {avg_loss:.5f} | Train: {train_acc:.2f}% | Test: {test_acc:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"{save_dir}/model_epoch_{epochs}.pth\")\n",
    "print(f\"权重保存至 {save_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec9030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可视化结果已保存：results/task2/predictions.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12358/2933527604.py:64: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "#可视化\n",
    "import random\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "correct_imgs = []\n",
    "wrong_imgs = []\n",
    "\n",
    "classes = train_dataset.classes\n",
    "\n",
    "# CIFAR10 归一化参数（用于反归一化）\n",
    "cifar10_mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "cifar10_std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        for i in range(inputs.size(0)):\n",
    "            # 反归一化还原原图\n",
    "            img = inputs[i].cpu() * cifar10_std + cifar10_mean\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            true_label = labels[i].item()\n",
    "            pred_label = predicted[i].item()\n",
    "\n",
    "            if pred_label == true_label and len(correct_imgs) < 50:\n",
    "                correct_imgs.append((img, true_label, pred_label))\n",
    "            elif pred_label != true_label and len(wrong_imgs) < 50:\n",
    "                wrong_imgs.append((img, true_label, pred_label))\n",
    "\n",
    "        if len(correct_imgs) >= 50 and len(wrong_imgs) >= 50:\n",
    "            break\n",
    "\n",
    "# 随机选取5张\n",
    "random.seed(42)\n",
    "correct_samples = random.sample(correct_imgs, min(5, len(correct_imgs)))\n",
    "wrong_samples = random.sample(wrong_imgs, min(5, len(wrong_imgs)))\n",
    "\n",
    "# 保存可视化结果：2行5列，每个子图单独放大渲染\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 9), dpi=300)\n",
    "\n",
    "# 第一行：预测成功\n",
    "for i, (img, true_label, pred_label) in enumerate(correct_samples):\n",
    "    axes[0, i].imshow(img.permute(1, 2, 0).numpy(), interpolation='nearest')\n",
    "    axes[0, i].set_title(f'{classes[true_label]}', color='green', fontsize=14, fontweight='bold')\n",
    "    axes[0, i].axis('off')\n",
    "axes[0, 0].set_ylabel('Correct', fontsize=16, color='green', fontweight='bold')\n",
    "\n",
    "# 第二行：预测失败\n",
    "for i, (img, true_label, pred_label) in enumerate(wrong_samples):\n",
    "    axes[1, i].imshow(img.permute(1, 2, 0).numpy(), interpolation='nearest')\n",
    "    axes[1, i].set_title(f'Pred: {classes[pred_label]}\\nReal: {classes[true_label]}', color='red', fontsize=11, fontweight='bold')\n",
    "    axes[1, i].axis('off')\n",
    "axes[1, 0].set_ylabel('Wrong', fontsize=16, color='red', fontweight='bold')\n",
    "\n",
    "plt.suptitle('CIFAR-10 Predictions', fontsize=20, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_dir}/predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"可视化结果已保存：{save_dir}/predictions.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

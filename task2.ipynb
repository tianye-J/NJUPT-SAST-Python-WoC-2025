{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381f6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入模块与超参数设置\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# 训练超参数\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "save_dir = \"results/task2\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e5d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: 50000 张图片\n",
      "测试集: 10000 张图片\n",
      "类别: ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "from datasets import CIFAR10Dataset\n",
    "\n",
    "train_dataset = CIFAR10Dataset(root_dir='./DS/CIFAR10', train=True)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_dataset = CIFAR10Dataset(root_dir='./DS/CIFAR10', train=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "print(f\"训练集: {len(train_dataset)} 张图片\")\n",
    "print(f\"测试集: {len(test_dataset)} 张图片\")\n",
    "print(f\"类别: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbbf810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # CIFAR10 输入: (batch, 3, 32, 32)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "        self.dropout_conv = nn.Dropout(0.25)\n",
    "        self.dropout_fc = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 第一组: 32x32 -> 16x16\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        # 第二组: 16x16 -> 8x8\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        # 第三组: 8x8 -> 4x4\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout_conv(x)\n",
    "\n",
    "        # 全连接层\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout_fc(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#准备模型、Loss、优化器\n",
    "model = Net()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77f84f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练！批次大小：64, 共 100 轮\n",
      "\n",
      "Epoch [  1/100] Loss: 2.30324 | Train Acc: 9.71% | Test Acc: 10.00%\n",
      "Epoch [  2/100] Loss: 2.30268 | Train Acc: 9.97% | Test Acc: 11.57%\n",
      "Epoch [  3/100] Loss: 2.30245 | Train Acc: 10.23% | Test Acc: 10.00%\n",
      "Epoch [  4/100] Loss: 2.30196 | Train Acc: 10.65% | Test Acc: 13.62%\n",
      "Epoch [  5/100] Loss: 2.29566 | Train Acc: 12.38% | Test Acc: 12.13%\n",
      "Epoch [  6/100] Loss: 2.21499 | Train Acc: 17.61% | Test Acc: 23.82%\n",
      "Epoch [  7/100] Loss: 2.10994 | Train Acc: 23.20% | Test Acc: 26.63%\n",
      "Epoch [  8/100] Loss: 2.03112 | Train Acc: 25.06% | Test Acc: 28.21%\n",
      "Epoch [  9/100] Loss: 1.93735 | Train Acc: 26.72% | Test Acc: 31.50%\n",
      "Epoch [ 10/100] Loss: 1.85568 | Train Acc: 28.90% | Test Acc: 32.88%\n",
      "Epoch [ 11/100] Loss: 1.79688 | Train Acc: 31.32% | Test Acc: 35.13%\n",
      "Epoch [ 12/100] Loss: 1.73280 | Train Acc: 34.25% | Test Acc: 39.66%\n",
      "Epoch [ 13/100] Loss: 1.67069 | Train Acc: 37.33% | Test Acc: 41.63%\n",
      "Epoch [ 14/100] Loss: 1.62774 | Train Acc: 39.03% | Test Acc: 43.95%\n",
      "Epoch [ 15/100] Loss: 1.57159 | Train Acc: 41.71% | Test Acc: 46.48%\n",
      "Epoch [ 16/100] Loss: 1.52240 | Train Acc: 43.56% | Test Acc: 47.71%\n",
      "Epoch [ 17/100] Loss: 1.47287 | Train Acc: 45.64% | Test Acc: 50.04%\n",
      "Epoch [ 18/100] Loss: 1.42732 | Train Acc: 47.91% | Test Acc: 52.17%\n",
      "Epoch [ 19/100] Loss: 1.38586 | Train Acc: 49.09% | Test Acc: 53.65%\n",
      "Epoch [ 20/100] Loss: 1.33946 | Train Acc: 51.36% | Test Acc: 55.82%\n",
      "Epoch [ 21/100] Loss: 1.29859 | Train Acc: 52.88% | Test Acc: 57.64%\n",
      "Epoch [ 22/100] Loss: 1.25851 | Train Acc: 54.47% | Test Acc: 58.65%\n",
      "Epoch [ 23/100] Loss: 1.22068 | Train Acc: 56.30% | Test Acc: 60.37%\n",
      "Epoch [ 24/100] Loss: 1.18430 | Train Acc: 57.73% | Test Acc: 61.64%\n",
      "Epoch [ 25/100] Loss: 1.15608 | Train Acc: 58.53% | Test Acc: 63.28%\n",
      "Epoch [ 26/100] Loss: 1.12072 | Train Acc: 60.45% | Test Acc: 63.76%\n",
      "Epoch [ 27/100] Loss: 1.08656 | Train Acc: 61.55% | Test Acc: 65.82%\n",
      "Epoch [ 28/100] Loss: 1.05595 | Train Acc: 62.47% | Test Acc: 65.84%\n",
      "Epoch [ 29/100] Loss: 1.02823 | Train Acc: 63.80% | Test Acc: 67.17%\n",
      "Epoch [ 30/100] Loss: 0.99911 | Train Acc: 65.24% | Test Acc: 68.04%\n",
      "Epoch [ 31/100] Loss: 0.97821 | Train Acc: 65.68% | Test Acc: 68.97%\n",
      "Epoch [ 32/100] Loss: 0.95900 | Train Acc: 66.61% | Test Acc: 69.59%\n",
      "Epoch [ 33/100] Loss: 0.92972 | Train Acc: 67.57% | Test Acc: 70.42%\n",
      "Epoch [ 34/100] Loss: 0.91296 | Train Acc: 68.40% | Test Acc: 71.65%\n",
      "Epoch [ 35/100] Loss: 0.88872 | Train Acc: 69.14% | Test Acc: 70.52%\n",
      "Epoch [ 36/100] Loss: 0.86944 | Train Acc: 69.75% | Test Acc: 72.92%\n",
      "Epoch [ 37/100] Loss: 0.84855 | Train Acc: 70.61% | Test Acc: 73.40%\n",
      "Epoch [ 38/100] Loss: 0.83154 | Train Acc: 71.28% | Test Acc: 73.02%\n",
      "Epoch [ 39/100] Loss: 0.81584 | Train Acc: 72.01% | Test Acc: 73.68%\n",
      "Epoch [ 40/100] Loss: 0.80084 | Train Acc: 72.39% | Test Acc: 74.30%\n",
      "Epoch [ 41/100] Loss: 0.78012 | Train Acc: 73.42% | Test Acc: 75.13%\n",
      "Epoch [ 42/100] Loss: 0.76552 | Train Acc: 73.72% | Test Acc: 75.51%\n",
      "Epoch [ 43/100] Loss: 0.75526 | Train Acc: 74.26% | Test Acc: 75.75%\n",
      "Epoch [ 44/100] Loss: 0.73519 | Train Acc: 74.66% | Test Acc: 75.57%\n",
      "Epoch [ 45/100] Loss: 0.73012 | Train Acc: 75.13% | Test Acc: 76.91%\n",
      "Epoch [ 46/100] Loss: 0.71596 | Train Acc: 75.68% | Test Acc: 77.20%\n",
      "Epoch [ 47/100] Loss: 0.69515 | Train Acc: 76.25% | Test Acc: 77.09%\n",
      "Epoch [ 48/100] Loss: 0.68235 | Train Acc: 76.75% | Test Acc: 78.07%\n",
      "Epoch [ 49/100] Loss: 0.67728 | Train Acc: 76.87% | Test Acc: 78.40%\n",
      "Epoch [ 50/100] Loss: 0.65841 | Train Acc: 77.57% | Test Acc: 78.11%\n",
      "Epoch [ 51/100] Loss: 0.64881 | Train Acc: 78.06% | Test Acc: 78.36%\n",
      "Epoch [ 52/100] Loss: 0.63584 | Train Acc: 78.13% | Test Acc: 78.88%\n",
      "Epoch [ 53/100] Loss: 0.62677 | Train Acc: 78.73% | Test Acc: 79.42%\n",
      "Epoch [ 54/100] Loss: 0.61794 | Train Acc: 78.90% | Test Acc: 79.34%\n",
      "Epoch [ 55/100] Loss: 0.60233 | Train Acc: 79.50% | Test Acc: 79.57%\n",
      "Epoch [ 56/100] Loss: 0.59512 | Train Acc: 79.96% | Test Acc: 79.49%\n",
      "Epoch [ 57/100] Loss: 0.58900 | Train Acc: 79.98% | Test Acc: 80.04%\n",
      "Epoch [ 58/100] Loss: 0.57497 | Train Acc: 80.41% | Test Acc: 80.14%\n",
      "Epoch [ 59/100] Loss: 0.56848 | Train Acc: 80.74% | Test Acc: 80.08%\n",
      "Epoch [ 60/100] Loss: 0.55443 | Train Acc: 81.10% | Test Acc: 80.73%\n",
      "Epoch [ 61/100] Loss: 0.55116 | Train Acc: 81.27% | Test Acc: 80.69%\n",
      "Epoch [ 62/100] Loss: 0.54575 | Train Acc: 81.55% | Test Acc: 80.96%\n",
      "Epoch [ 63/100] Loss: 0.53038 | Train Acc: 81.95% | Test Acc: 80.67%\n",
      "Epoch [ 64/100] Loss: 0.52340 | Train Acc: 82.06% | Test Acc: 80.67%\n",
      "Epoch [ 65/100] Loss: 0.51791 | Train Acc: 82.48% | Test Acc: 81.78%\n",
      "Epoch [ 66/100] Loss: 0.50462 | Train Acc: 82.79% | Test Acc: 81.02%\n",
      "Epoch [ 67/100] Loss: 0.50124 | Train Acc: 82.97% | Test Acc: 81.73%\n",
      "Epoch [ 68/100] Loss: 0.49438 | Train Acc: 83.38% | Test Acc: 81.85%\n",
      "Epoch [ 69/100] Loss: 0.48958 | Train Acc: 83.28% | Test Acc: 81.78%\n",
      "Epoch [ 70/100] Loss: 0.47843 | Train Acc: 83.72% | Test Acc: 82.11%\n",
      "Epoch [ 71/100] Loss: 0.47186 | Train Acc: 84.05% | Test Acc: 82.13%\n",
      "Epoch [ 72/100] Loss: 0.46823 | Train Acc: 84.27% | Test Acc: 81.77%\n",
      "Epoch [ 73/100] Loss: 0.45747 | Train Acc: 84.33% | Test Acc: 82.05%\n",
      "Epoch [ 74/100] Loss: 0.44918 | Train Acc: 84.68% | Test Acc: 81.27%\n",
      "Epoch [ 75/100] Loss: 0.44773 | Train Acc: 84.63% | Test Acc: 82.36%\n",
      "Epoch [ 76/100] Loss: 0.43926 | Train Acc: 85.15% | Test Acc: 82.71%\n",
      "Epoch [ 77/100] Loss: 0.42859 | Train Acc: 85.44% | Test Acc: 82.19%\n",
      "Epoch [ 78/100] Loss: 0.42719 | Train Acc: 85.35% | Test Acc: 82.44%\n",
      "Epoch [ 79/100] Loss: 0.42431 | Train Acc: 85.57% | Test Acc: 82.03%\n",
      "Epoch [ 80/100] Loss: 0.41235 | Train Acc: 86.10% | Test Acc: 82.96%\n",
      "Epoch [ 81/100] Loss: 0.40742 | Train Acc: 86.10% | Test Acc: 83.00%\n",
      "Epoch [ 82/100] Loss: 0.40395 | Train Acc: 86.35% | Test Acc: 82.78%\n",
      "Epoch [ 83/100] Loss: 0.40165 | Train Acc: 86.48% | Test Acc: 82.90%\n",
      "Epoch [ 84/100] Loss: 0.39596 | Train Acc: 86.49% | Test Acc: 83.08%\n",
      "Epoch [ 85/100] Loss: 0.39185 | Train Acc: 86.76% | Test Acc: 83.28%\n",
      "Epoch [ 86/100] Loss: 0.37554 | Train Acc: 87.07% | Test Acc: 83.02%\n",
      "Epoch [ 87/100] Loss: 0.37900 | Train Acc: 86.98% | Test Acc: 83.64%\n",
      "Epoch [ 88/100] Loss: 0.36989 | Train Acc: 87.29% | Test Acc: 83.54%\n",
      "Epoch [ 89/100] Loss: 0.36567 | Train Acc: 87.53% | Test Acc: 83.59%\n",
      "Epoch [ 90/100] Loss: 0.36585 | Train Acc: 87.46% | Test Acc: 83.53%\n",
      "Epoch [ 91/100] Loss: 0.35913 | Train Acc: 87.92% | Test Acc: 83.43%\n",
      "Epoch [ 92/100] Loss: 0.35978 | Train Acc: 87.93% | Test Acc: 83.46%\n",
      "Epoch [ 93/100] Loss: 0.34790 | Train Acc: 88.31% | Test Acc: 83.37%\n",
      "Epoch [ 94/100] Loss: 0.34224 | Train Acc: 88.32% | Test Acc: 83.40%\n",
      "Epoch [ 95/100] Loss: 0.34233 | Train Acc: 88.36% | Test Acc: 83.80%\n",
      "Epoch [ 96/100] Loss: 0.33365 | Train Acc: 88.63% | Test Acc: 83.90%\n",
      "Epoch [ 97/100] Loss: 0.33669 | Train Acc: 88.54% | Test Acc: 83.80%\n",
      "Epoch [ 98/100] Loss: 0.32985 | Train Acc: 88.77% | Test Acc: 84.02%\n",
      "Epoch [ 99/100] Loss: 0.32832 | Train Acc: 88.77% | Test Acc: 84.09%\n",
      "Epoch [100/100] Loss: 0.31600 | Train Acc: 89.30% | Test Acc: 83.66%\n",
      "\n",
      "训练完成 :)\n",
      "模型权重已保存：results/task2/model_epoch_100.pth\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "print(f\"开始训练！批次大小：{batch_size}, 共 {epochs} 轮\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # 计算平均指标\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    # 测试集评估\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1:3d}/{epochs}] Loss: {avg_loss:.5f} | Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "#保存模型权重\n",
    "torch.save(model.state_dict(), f\"{save_dir}/model_epoch_{epochs}.pth\")\n",
    "print(f\"\\n训练完成 :)\")\n",
    "print(f\"模型权重已保存：{save_dir}/model_epoch_{epochs}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec9030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可视化结果已保存：results/task2/predictions.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6150/655398255.py:64: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "#可视化\n",
    "import random\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "correct_imgs = []  # (img_tensor, true_label, pred_label)\n",
    "wrong_imgs = []\n",
    "\n",
    "classes = train_dataset.classes\n",
    "\n",
    "# CIFAR10 归一化参数（用于反归一化）\n",
    "cifar10_mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "cifar10_std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        for i in range(inputs.size(0)):\n",
    "            # 反归一化还原原图\n",
    "            img = inputs[i].cpu() * cifar10_std + cifar10_mean\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            true_label = labels[i].item()\n",
    "            pred_label = predicted[i].item()\n",
    "\n",
    "            if pred_label == true_label and len(correct_imgs) < 50:\n",
    "                correct_imgs.append((img, true_label, pred_label))\n",
    "            elif pred_label != true_label and len(wrong_imgs) < 50:\n",
    "                wrong_imgs.append((img, true_label, pred_label))\n",
    "\n",
    "        if len(correct_imgs) >= 50 and len(wrong_imgs) >= 50:\n",
    "            break\n",
    "\n",
    "# 随机选取5张\n",
    "random.seed(42)\n",
    "correct_samples = random.sample(correct_imgs, min(5, len(correct_imgs)))\n",
    "wrong_samples = random.sample(wrong_imgs, min(5, len(wrong_imgs)))\n",
    "\n",
    "# 保存可视化结果：2行5列，每个子图单独放大渲染\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 9), dpi=300)\n",
    "\n",
    "# 第一行：预测成功\n",
    "for i, (img, true_label, pred_label) in enumerate(correct_samples):\n",
    "    axes[0, i].imshow(img.permute(1, 2, 0).numpy(), interpolation='nearest')\n",
    "    axes[0, i].set_title(f'{classes[true_label]}', color='green', fontsize=14, fontweight='bold')\n",
    "    axes[0, i].axis('off')\n",
    "axes[0, 0].set_ylabel('Correct', fontsize=16, color='green', fontweight='bold')\n",
    "\n",
    "# 第二行：预测失败\n",
    "for i, (img, true_label, pred_label) in enumerate(wrong_samples):\n",
    "    axes[1, i].imshow(img.permute(1, 2, 0).numpy(), interpolation='nearest')\n",
    "    axes[1, i].set_title(f'Pred: {classes[pred_label]}\\nReal: {classes[true_label]}', color='red', fontsize=11, fontweight='bold')\n",
    "    axes[1, i].axis('off')\n",
    "axes[1, 0].set_ylabel('Wrong', fontsize=16, color='red', fontweight='bold')\n",
    "\n",
    "plt.suptitle('CIFAR-10 Predictions', fontsize=20, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_dir}/predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"可视化结果已保存：{save_dir}/predictions.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
